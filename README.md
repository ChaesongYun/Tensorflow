![image](https://github.com/ChaesongYun/Tensorflow/assets/139418987/deb37252-129c-461e-a891-59f650c26815)

# 선형회귀
변수 사이의 선형적인 관계를 모델링한 것
<br>
<br>

### 선형적이다
- 데이터가 직선적인 관계를 가진다
- ex) 성실히 팔수록 많은 돈을 벌 수 있을 것이다<br>
  -> 하루에 일하는 시간과 매출은 서로 어떤 관계를 가질까?
- 선형적인 관계에 적용하는 대표적인 기계학습이론이 선형 회귀이다
<br>
<br>

### 학습을 시킨다
- 주어진 데이터를 학습시켜서 가장 합리적인 '직선'을 찾아내는 것
- 데이터는 3개 이상일 때 의미가 있다
- 데이터가 2개라면 단순히 두 직선을 이은 것밖에 안되니까!
<br>
<br>

### 가설
- H(x) = Wx + b
- 하나의 일차방정식을 이용해 직선을 표현한다
- 가설을 수정해 나가면서 가장 합리적인 식을 찾아낸다!
<br>
<br>

### 결론
- 선형회귀란 주어진 데이터를 이용해 일차방정식을 수정해나가는 것
- 학습을 거쳐서 가장 합리적인 선을 찾아내는 것
- 학습을 많이 해도 '완벽한' 식을 찾아내지 못할 수 있다
- 실제 사례에서는 근사값을 찾는 것만으로도 충분할 때가 많다
- 알파고도 결과적으로는 '근사값'을 가정하는 프로그램에 불과
<br>
<br>

---
<br>
<br>

## 비용
- 가설이 얼마나 정확한지 판단하는 기준
- (예측값 - 실제값)^2 의 평균
<br> 거리이기 때문에 음수가 나오면 안됨
- 현재의 W, b값과 데이터를 이용하면 비용함수를 구할 수 있다
- 비용함수로 구한 비용이 적을수록 좋다
<br>
<br>

### 경사 하강(Gradient Descent)
- H(x) = Wx로 식을 간단히 한다
- 따라서 비용함수는 (Wx-y)^2를 따른다
<br>
<br>

### 핵심
- 곡선의 특성상 초반에 많은 폭으로 변화한다
- 너무 작게 점프하면 오랫동안 학습해야 한다
- 너무 크게 점프하면 학습 결과가 부정확할 수 있다
<br>
<br>


